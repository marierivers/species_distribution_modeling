---
title: "species"
author: "Marie Rivers"
date: "1/5/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```
# Species Distribution Modeling
# Part 1: Explore
## Install Packages
```{r}
# load packages, installing if missing
if (!require(librarian)){
  install.packages("librarian")
  library(librarian)
}
librarian::shelf(
  dismo, dplyr, DT, ggplot2, here, htmltools, leaflet, mapview, purrr, raster, readr, rgbif, rgdal, rJava, sdmpredictors, sf, spocc, tidyr)
select <- dplyr::select # overwrite raster::select
options(readr.show_col_types = FALSE)
```

```{r}
# set random seed for reproducibility
set.seed(42)
```

```{r}
# directory to store data
dir_data <- here("data/sdm")
dir.create(dir_data, showWarnings = F, recursive = T)
```

## Get Species Observations
```{r}
obs_csv <- file.path(dir_data, "obs.csv")
obs_geo <- file.path(dir_data, "obs.geojson")
redo    <- TRUE # change back to FALSE...xxx

if (!file.exists(obs_geo) | redo){
  # get species occurrence data from GBIF with coordinates
  (res <- spocc::occ(
    query = 'Haliaeetus leucocephalus', 
    from = 'gbif', has_coords = T, limit = 10000))
  
  # extract data frame from result
  df <- res$gbif$data[[1]] 
  readr::write_csv(df, obs_csv)
  
  # convert to points of observation from lon/lat columns in data frame
  obs <- df %>% 
    sf::st_as_sf(
      coords = c("longitude", "latitude"),
      crs = st_crs(4326)) %>% 
    select(prov, key, issues, basisOfRecord, occurrenceStatus, eventDate, isInCluster, lifeStage, locality, collectionCode, recordedBy, fieldNotes, eventTime, behavior, verbatimElevation, lifeStage, dateIdentified, stateProvince, verbatimLocality, occurrenceRemarks, identificationID, occurrenceRemarks, informationWithheld, identificationRemarks) # save space (joinable from obs_csv)
  sf::write_sf(obs, obs_geo, delete_dsn=T)
}
obs <- sf::read_sf(obs_geo)
nrow(obs) # number of rows
```

## check for duplicate observations
```{r}
duplicates <- duplicated(df$)
sum(duplicates)

df_dup_check <- df %>% 
  mutate(dups = duplicates)
```
```{r}
duplicates <- duplicated(obs$geometry)
sum(duplicates)

obs_dup_check <- obs %>% 
  mutate(dups = duplicates)
```


```{r}
# show points on map
mapview::mapview(obs, map.types = "Esri.WorldPhysical")
```

**Question 1**
There are a total of 3,943,548 observations for bald eagle in the GBIF database. For this model, I limited the number of observations to 10,000.

**Question 2**
xxx...odd observations

## Get Environmental Data
### Presence
```{r}
dir_env <- file.path(dir_data, "env")

# set a default data directory
options(sdmpredictors_datadir = dir_env)

# choosing terrestrial
env_datasets <- sdmpredictors::list_datasets(terrestrial = TRUE, marine = FALSE)

# show table of datasets
env_datasets %>% 
  select(dataset_code, description, citation) %>% 
  DT::datatable()
```

```{r}
# choose datasets for a vector
env_datasets_vec <- c("WorldClim", "ENVIREM")

# get layers
env_layers <- sdmpredictors::list_layers(env_datasets_vec)
DT::datatable(env_layers)
```

```{r}
# choose layers after some inspection and perhaps consulting literature
env_layers_vec <- c("WC_alt", "WC_bio1", "WC_bio2", "ER_tri", "ER_topoWet")

# get layers
env_stack <- load_layers(env_layers_vec)

# interactive plot layers, hiding all but first (select others)
# mapview(env_stack, hide = T) # makes the html too big for Github
plot(env_stack, nc=2)
```

```{r}
# crop the environmental rasters to a reasonable study area around our species observations
obs_hull_geo  <- file.path(dir_data, "obs_hull.geojson")
env_stack_grd <- file.path(dir_data, "env_stack.grd")

if (!file.exists(obs_hull_geo) | redo){
  # make convex hull around points of observation
  obs_hull <- sf::st_convex_hull(st_union(obs))
  
  # save obs hull
  write_sf(obs_hull, obs_hull_geo)
}
obs_hull <- read_sf(obs_hull_geo)

# show points on map
mapview(
  list(obs, obs_hull))
```

```{r}
if (!file.exists(env_stack_grd) | redo){
  obs_hull_sp <- sf::as_Spatial(obs_hull)
  env_stack <- raster::mask(env_stack, obs_hull_sp) %>% 
    raster::crop(extent(obs_hull_sp))
  writeRaster(env_stack, env_stack_grd, overwrite=T)  
}
env_stack <- stack(env_stack_grd)

# show map
# mapview(obs) + 
#   mapview(env_stack, hide = T) # makes html too big for Github
plot(env_stack, nc=2)
```

### Pseudo-Absence
```{r}
absence_geo <- file.path(dir_data, "absence.geojson")
pts_geo     <- file.path(dir_data, "pts.geojson")
pts_env_csv <- file.path(dir_data, "pts_env.csv")

if (!file.exists(absence_geo) | redo){
  # get raster count of observations
  r_obs <- rasterize(
    sf::as_Spatial(obs), env_stack[[1]], field=1, fun='count')
  
  # show map
  # mapview(obs) + 
  #   mapview(r_obs)
  
  # create mask for 
  r_mask <- mask(env_stack[[1]] > -Inf, r_obs, inverse=T)
  
  # generate random points inside mask
  absence <- dismo::randomPoints(r_mask, nrow(obs)) %>% 
    as_tibble() %>% 
    st_as_sf(coords = c("x", "y"), crs = 4326)
  
  write_sf(absence, absence_geo, delete_dsn=T)
}
absence <- read_sf(absence_geo)

# show map of presence, ie obs, and absence
mapview(obs, col.regions = "green") + 
  mapview(absence, col.regions = "gray")
```

```{r}
if (!file.exists(pts_env_csv) | redo){

  # combine presence and absence into single set of labeled points 
  pts <- rbind(
    obs %>% 
      mutate(
        present = 1) %>% 
      select(present, key),
    absence %>% 
      mutate(
        present = 0,
        key     = NA)) %>% 
    mutate(
      ID = 1:n()) %>% 
    relocate(ID)
  write_sf(pts, pts_geo, delete_dsn=T)

  # extract raster values for points
  pts_env <- raster::extract(env_stack, as_Spatial(pts), df=TRUE) %>% 
    tibble() %>% 
    # join present and geometry columns to raster value results for points
    left_join(
      pts %>% 
        select(ID, present),
      by = "ID") %>% 
    relocate(present, .after = ID) %>% 
    # extract lon, lat as single columns
    mutate(
      #present = factor(present),
      lon = st_coordinates(geometry)[,1],
      lat = st_coordinates(geometry)[,2]) %>% 
    select(-geometry)
  write_csv(pts_env, pts_env_csv)
}
pts_env <- read_csv(pts_env_csv)

pts_env %>% 
  # show first 10 presence, last 10 absence
  slice(c(1:10, (nrow(pts_env)-9):nrow(pts_env))) %>% 
  DT::datatable(
    rownames = F,
    options = list(
      dom = "t",
      pageLength = 20))
```
```{r}
nrow(pts_env)
```

```{r}
datatable(pts_env, rownames = F)
```

## Term Plots
The term plots display predictors and responses. For modeling purposes, predictors are preferred where presence occupies a distinct niche from the background absence points. The term plots are a good way visualize how differentiated presence is from absence for each predictor.
```{r}
pts_env %>% 
  select(-ID) %>% 
  mutate(
    present = factor(present)) %>% 
  pivot_longer(-present) %>% 
  ggplot() +
  geom_density(aes(x = value, fill = present)) + 
  scale_fill_manual(values = alpha(c("gray", "green"), 0.5)) +
  scale_x_continuous(expand=c(0,0)) +
  scale_y_continuous(expand=c(0,0)) +
  theme_bw() + 
  facet_wrap(~name, scales = "free") +
  theme(
    legend.position = c(1, 0),
    legend.justification = c(1, 0))
```
Based on the results of Term Plots, topographic wetness (ER_topoWet) and terrain roughness index (ER_tri) are similarly distributed for presence and absence points and are therefore likely not strong predictors for a bald eagle species distribution model.
xxx...try adding other predictors

## Pairs plot to show correlations between variables
```{r}
GGally::ggpairs(
  select(pts_env, -ID),
  aes(color = factor(present), alpha = 0.5))
```
Based on the results of the pairs plots, the most strongly correlated environmental predictors are topographic wetness (ER_topoWet) and terrain roughness index (ER_tri).

# Part 2: Logistic Regression
## Setup Data
- Drop rows with any NAs
- remove terms we don't want to model
- use a simplified formula `_present_ ~.` to predict where the species is present based on all other fields in the data from (ie. y ~ X1 + X2 + ...Xn)
```{r}
d <- pts_env %>% 
  select(-ID) %>% # remove terms we don't want to model 
  tidyr::drop_na() # drop the rows with NA values
nrow(d)
```

## Linear Model
```{r}
# fit a linear model
mdl_linear <- lm(present ~ ., data = d)
summary(mdl_linear)
```

```{r}
y_predict <- predict(mdl_linear, d, type="response")
y_true <- d$present
range(y_predict)
```
```{r}
range(y_true)
```
An issue with this linear model is that the predicted response is not limited to a binary 0 or 1 to represent absence or precense.

## Generalized Linear Model
This model constrains the response to be closer to the range from 0 to 1.
```{r}
# fit a generalized linear model with a binomial logit link function
mdl_glm <- glm(present ~ ., family = binomial(link="logit"), data = d)
summary(mdl_glm)
```
```{r}
y_predict_glm <- predict(mdl_glm, d, type = "response")
range(y_predict_glm)
```

Look at the terms plots to see the relationship between predictor and response
```{r}
# show term plots
termplot(mdl_glm, partial.resid = TRUE, se = TRUE, main = F, ylim = "free")
```
## Generalize Additive Model
With a general additive model we can add "wiggle" to the relationship between predictor and response by introducing smooth s() terms
```{r}
librarian::shelf(mgcv)

# fit a generalized additive model with smooth predictors
mdl_gen_add <- mgcv::gam(
  formula = present ~ s(WC_alt) + s(WC_bio1) + s(WC_bio2) + s(ER_tri) + s(ER_topoWet) + s(lon) + s(lat),
  family = binomial, data = d)
summary(mdl_gen_add)
```
```{r}
# show term plot
plot(mdl_gen_add, scale=0)
```

## Maxent (Maximum Entropy)
Maxent is a commonly used species distribution model that performs well with few input data points, only requires presence points and is easy to use with a Java graphical user interface (GUI). Since this model only has presence points, it samples the background for comparision.
```{r}
# load extra packages
librarian::shelf(
  maptools, sf)

mdl_maxent_rds <- file.path(dir_data, "mdl_maxent.rds")

# show version of maxent
if (!interactive())
  maxent()
```
```{r}
# get environmental rasters
# NOTE: the first part of Lab 1. SDM - Explore got updated to write this clipped environmental raster stack

# env_stack_grd <- file.path(dir_data, "env_stack.grd")
# env_stack <- stack(env_stack_grd)
# plot(env_stack, nc=2)
```

```{r}
# get the presence-only observation points (maxent extracts raster values for you)
# obs_geo2<- file.path(dir_data, "obs")
obs_sp <- read_sf(obs_geo) %>%
  sf::as_Spatial() # maxent prefers sp::SpatialPoints over newer sf::sf class

# fit a maxent entropy model
if (!file.exists(mdl_maxent_rds)){
  mdl_maxent <- maxent(env_stack, obs_sp)
  readr::write_rds(mdl_maxent, mdl_maxent_rds)
}
mdl_maxent <- read_rds(mdl_maxent_rds)
```

```{r}
# plot variable contributions per predictor
plot(mdl_maxent)
```
```{r}
# plot term plots
response(mdl_maxent)
```
```{r}
# predict
y_predict_maxent <- predict(env_stack, mdl_maxent) #, ext=ext, progress='')

plot(y_predict_maxent, main='Maxent, raw prediction')
data(wrld_simpl, package = "maptools")
plot(wrld_simpl, add=TRUE, border='dark grey')
```
# Part 3: Decision Trees
Use decision trees as a classification technique to the data with the response being categorical (factor(present))
```{r}
# load packages
librarian:::shelf(
  caret, # X: modeling framework
  dplyr, ggplot, here, reader, 
  pdp, # X: partial dependence plots
  rpart, # m: recursive partition modeling
  rpart.plot, # m: recusive partition plotting
  rsample, # d: split train/test data
  skimr, # d: skim summarize data table
  vip) # X: variable importance
```
```{r}
# options
options(
  scipen = 999,
  readr.show_col_types = F)
set.seed(42)

# graphical theme
ggplot2::theme_set(ggplot2::theme_light())

# paths
# dir_data    <- here("data/sdm")
# pts_env_csv <- file.path(dir_data, "pts_env.csv")

# read data
# pts_env <- read_csv(pts_env_csv)
d <- pts_env %>% 
  select(-ID) %>% # not used as a predictor x
  mutate(
    present = factor(present)) %>% 
  na.omit()
skim(d)
```

## Split data into training and testing
```{r}
# create training set with 80% of full data
d_split <- rsample::initial_split(d, prop = 0.8, strata = "present")
d_train <- rsample::training(d_split)

# show number of rows present in 0 vs 1
table(d$present)
```
```{r}
table(d_train$present)
```
## Partition, depth=1
```{r}
# run decision stump model
mdl_stump <- rpart(
  present ~ ., data = d_train,
  control = list(
    cp = 0, minbucket = 5, maxdepth = 1))
mdl_stump
```

```{r}
# plot tree
par(mar = c(1, 1, 1, 1))
rpart.plot(mdl_stump)
```

## Partition, depth=default
```{r}
# decision tree with defaults
mdl_default_tree <- rpart(present ~ ., data = d_train)
mdl_default_tree
```

```{r}
rpart.plot(mdl_default_tree)
```
```{r}
# plot complexity parameter
plotcp(mdl_default_tree)
```
```{r}
# rpart cross validation results
mdl_default_tree$cptable
```

## Feature Interpretation
```{r}
# caret cross validation results
mdl_caret <- train(
  present ~ .,
  data = d_train,
  method = "rpart",
  trControl = trainControl(method = "cv", number = 10),
  tuneLength = 20)

ggplot(mdl_caret)
```

```{r}
vip(mdl_caret, num_features = 40, bar = FALSE)
```
```{r}
# construct partial dependence plots
p1 <- partial(mdl_caret, pred.var = "lat") %>%  autoplot()
p2 <- partial(mdl_caret, pred.var = "WC_bio2") %>% autoplot()
p3 <- partial(mdl_caret, pred.var = c("lat", "WC_bio2")) %>% 
  plotPartial(levelplot = FALSE, zlab = "yhat", drape = TRUE,
              colorkey = TRUE, screen = list(z = -20, x = -60))
```

```{r}
# display plots side by side
gridExtra::grid.arrange(p1, p2, p3, ncol = 3)
```
## Random Forests
```{r}
# load additional packages
librarian::shelf(
  ranger) # random forest modeling
```

### Fit
```{r}
# number of features
n_features <- length(setdiff(names(d_train), "present"))

# fit a default random forest model
mdl_rf <- ranger(present ~ ., data = d_train)

# get out of the box RMSE
(default_rmse <- sqrt(mdl_rf$prediction.error))
```
### Feature Interpretation
```{r}
# re-run model with impurity-based variable importance
mdl_impurity <- ranger(
  present ~ ., data = d_train,
  importance = "impurity")

# re-run model with permutation-based variable importance
mdl_permutation <- ranger(
  present ~ ., data = d_train,
  importance = "permutation")
```

```{r}
p1_rf <- vip::vip(mdl_impurity, bar = FALSE)
p2_rf <- vip::vip(mdl_permutation, bar = FALSE)

gridExtra::grid.arrange(p1_rf, p2_rf, nrow = 1)
```
# Part 4: Evaluate Models
```{r}
librarian::shelf(
  usdm) # uncertainty analysis for species distribution models: vifcor()
```

```{r}
# paths
mdl_maxv_rds <- file.path(dir_data, "mdl_maxent_vif.rds")
```

```{r}
# read points of observation: presence (1) and absence (0)
pts <- read_sf(pts_geo)
```

```{r}
# read raster stack of environment
env_stack < raster::stack(env_stack_grd)
```
## Split observations into training and testing
xxx...this was done around line 400
```{r}
pts_split <- rsample::initial_split(
  pts, prop = 0.8, strata = "present")
pts_train <- rsample::training(pts_split)
pts_test <- rsample::testing(pts_split)

pts_train_p <- pts_train %>% 
  filter(present == 1) %>% 
  as_Spatial()
pts_train_a <- pts_train %>% 
  filter(present == 0) %>% 
  as_Spatial()
```

# Calibrate: Model Selection
```{r}
# show pairs plot before multicollinearity reduction with vifcor()
pairs(env_stack)
```

```{r}
# calculate variance inflation factor per predictor, a metric of multicollinearity between variables
vif(env_stack)
```
```{r}
# stepwise reduce predictors based on a max correlation of 0.7 (max 1)
v <- vifcor(env_stack, th=0.7)
v
```

1 variables from the 5 input variables have collinearity problem: 
 
ER_tri 

After excluding the collinear variables, the linear correlation coefficients ranges between: 
min correlation ( ER_topoWet ~ WC_bio2 ):  0.06246968 
max correlation ( ER_topoWet ~ WC_alt ):  -0.5847924 

```{r}
# reduce environmental raster stack by
env_stack_v <- usdm::exclude(env_stack, v)

# show pairs plot after multicollinearity reduction with vifcor()
pairs(env_stack_v)
```
```{r}
# fit a maximum entropy model
if(!file.exists(mdl_maxv_rds)){
  mdl_maxv <- maxent(env_stack_v, sf::as_Spatial(pts_train))
  readr::write_rds(mdl_maxv, mdl_maxv_rds)
}
mdl_maxv <- read_rds(mdl_maxv_rds)
```

```{r}
# plot variable contributions per predictor
plot(mdl_maxv)
```
```{r}
# plot term plots
response(mdl_maxv)
```
```{r}
# predict
y_maxv <- predict(env_stack, mdl_maxv) # ext=ext, progress=''

plot(y_maxv, main='Maxent, raw prediction')
data("wrld_simpl", package="maptools")
plot(wrld_simpl, add=TRUE, border='dark grey')
```
# Evaluate: Model Performance
## Area Under the Curve (AUC), Reciever Operater Characteristic (ROC) Curve and Confustion Matrix
```{r}
pts_test_p <- pts_test %>% 
  filter(present == 1) %>% 
  as_Spatial()
pts_test_a <- pts_test %>% 
  filter(present == 0) %>% 
  as_Spatial()

y_maxv <- predict(mdl_maxv, env_stack)
# plot(y_maxv)

e <- dismo::evaluate(
  p = pts_test_p,
  a = pts_test_a,
  model = mdl_maxv,
  x = env_stack)
e
```
```{r}
plot(e, 'ROC')
```
```{r}
thr <- threshold(e)[['spec_sens']]
thr
```
```{r}
p_true <- na.omit(raster::extract(y_maxv, pts_test_p) >= thr)
a_true <- na.omit(raster::extract(y_maxv, pts_test_a) < thr)
```

```{r}
# (t)rue/(f)alse (p)positve/(n)negative rates
tpr <- sum(p_true)/length(p_true)
fnr <- sum(!p_true)/length(p_true)
fpr <- sum(!a_true)/length(a_true)
tnr <- sum(a_true)/length(a_true)
```

```{r}
matrix(
  c(tpr, fnr, fpr, tnr),
  nrow=2, dimnames = list(
    c('present_obs', 'absent_obs'),
    c('present_pred', 'absent_pred')))
```

```{r}
# add point to ROC plot
plot(e, 'ROC')
points(fpr, tpr, pch=23, bg='blue')
```
```{r}
plot(y_maxv > thr)
```

